{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "import boto3\n",
    "import folium\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from statsmodels.stats.weightstats import ttest_ind\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data_with_index_nodups.pkl',\n",
       " 'data_plus_census.pkl',\n",
       " 'data_with_index.csv',\n",
       " 'data_plus_census.csv',\n",
       " 'data_with_index.pkl',\n",
       " 'data_with_index_nodups.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/procesada')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AWS_ACCESS_KEY = ' AKIARQBCIP76L6XVXIVQ'\n",
    "AWS_SECRET_ACCESS_KEY = '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'\n",
    "S3_BUCKET_NAME = 'ds4ateam5'\n",
    "\n",
    "s3_client = boto3.resource(\n",
    "    's3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "s3_bucket = s3_client.Bucket(S3_BUCKET_NAME)\n",
    "local_folder = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**El siguiente código descargar solamente las bases procesasdas (con info de censo y codig de sector)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_folder = '.'\n",
    "files = ['data/procesada/data_plus_census.csv',\n",
    "        'data/procesada/data_plus_census.pkl']\n",
    "\n",
    "for obj in files:\n",
    "    local_file = os.path.join(local_folder, obj)\n",
    "    \n",
    "    for i in range(len(obj.split('/')[:-1])):\n",
    "        dir_name = '/'.join(obj.split('/')[0:i+1])\n",
    "        if not os.path.exists(dir_name):\n",
    "            os.makedirs(dir_name)\n",
    "        \n",
    "    s3_bucket.download_file(obj, local_file)\n",
    "    print(obj + '\\tdescargado')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/procesada/data_plus_census.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>census_code</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>final_decision</th>\n",
       "      <th>Cod_setor</th>\n",
       "      <th>DOMICILIO_RENDA_V001</th>\n",
       "      <th>DOMICILIO_RENDA_V002</th>\n",
       "      <th>DOMICILIO_RENDA_V003</th>\n",
       "      <th>DOMICILIO_RENDA_V004</th>\n",
       "      <th>...</th>\n",
       "      <th>Tipo_setor_7</th>\n",
       "      <th>Tipo_setor_8</th>\n",
       "      <th>Situacao_setor_1</th>\n",
       "      <th>Situacao_setor_2</th>\n",
       "      <th>Situacao_setor_3</th>\n",
       "      <th>Situacao_setor_4</th>\n",
       "      <th>Situacao_setor_5</th>\n",
       "      <th>Situacao_setor_6</th>\n",
       "      <th>Situacao_setor_7</th>\n",
       "      <th>Situacao_setor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.263983</td>\n",
       "      <td>-50.247906</td>\n",
       "      <td>R</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473449.0</td>\n",
       "      <td>473449.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.265123</td>\n",
       "      <td>-50.255143</td>\n",
       "      <td>R</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473449.0</td>\n",
       "      <td>473449.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.266660</td>\n",
       "      <td>-50.254667</td>\n",
       "      <td>A</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>0.0</td>\n",
       "      <td>473449.0</td>\n",
       "      <td>473449.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000058</td>\n",
       "      <td>-20.267959</td>\n",
       "      <td>-50.262205</td>\n",
       "      <td>R</td>\n",
       "      <td>351550905000058</td>\n",
       "      <td>1.0</td>\n",
       "      <td>543349.0</td>\n",
       "      <td>542449.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000042</td>\n",
       "      <td>-20.268545</td>\n",
       "      <td>-50.241478</td>\n",
       "      <td>R</td>\n",
       "      <td>351550905000042</td>\n",
       "      <td>0.0</td>\n",
       "      <td>326048.0</td>\n",
       "      <td>326048.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  state      census_code        lat       long final_decision  \\\n",
       "0    sp  351550905000079 -20.263983 -50.247906              R   \n",
       "1    sp  351550905000079 -20.265123 -50.255143              R   \n",
       "2    sp  351550905000079 -20.266660 -50.254667              A   \n",
       "3    sp  351550905000058 -20.267959 -50.262205              R   \n",
       "4    sp  351550905000042 -20.268545 -50.241478              R   \n",
       "\n",
       "         Cod_setor  DOMICILIO_RENDA_V001  DOMICILIO_RENDA_V002  \\\n",
       "0  351550905000079                   0.0              473449.0   \n",
       "1  351550905000079                   0.0              473449.0   \n",
       "2  351550905000079                   0.0              473449.0   \n",
       "3  351550905000058                   1.0              543349.0   \n",
       "4  351550905000042                   0.0              326048.0   \n",
       "\n",
       "   DOMICILIO_RENDA_V003  DOMICILIO_RENDA_V004  ...  Tipo_setor_7  \\\n",
       "0              473449.0                   0.0  ...           0.0   \n",
       "1              473449.0                   0.0  ...           0.0   \n",
       "2              473449.0                   0.0  ...           0.0   \n",
       "3              542449.0                 900.0  ...           0.0   \n",
       "4              326048.0                   0.0  ...           0.0   \n",
       "\n",
       "   Tipo_setor_8  Situacao_setor_1  Situacao_setor_2  Situacao_setor_3  \\\n",
       "0           0.0               1.0               0.0               0.0   \n",
       "1           0.0               1.0               0.0               0.0   \n",
       "2           0.0               1.0               0.0               0.0   \n",
       "3           0.0               1.0               0.0               0.0   \n",
       "4           0.0               1.0               0.0               0.0   \n",
       "\n",
       "   Situacao_setor_4  Situacao_setor_5  Situacao_setor_6  Situacao_setor_7  \\\n",
       "0               0.0               0.0               0.0               0.0   \n",
       "1               0.0               0.0               0.0               0.0   \n",
       "2               0.0               0.0               0.0               0.0   \n",
       "3               0.0               0.0               0.0               0.0   \n",
       "4               0.0               0.0               0.0               0.0   \n",
       "\n",
       "   Situacao_setor_8  \n",
       "0               0.0  \n",
       "1               0.0  \n",
       "2               0.0  \n",
       "3               0.0  \n",
       "4               0.0  \n",
       "\n",
       "[5 rows x 190 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32132, 190)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 32132 entries, 0 to 32131\n",
      "Data columns (total 13 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   state                32132 non-null  object\n",
      " 1   census_code          32132 non-null  object\n",
      " 2   final_decision       32132 non-null  object\n",
      " 3   Cod_setor            31927 non-null  object\n",
      " 4   Cod_Grandes Regiões  31927 non-null  object\n",
      " 5   Cod_RM               31927 non-null  object\n",
      " 6   Cod_UF               31927 non-null  object\n",
      " 7   Cod_bairro           31927 non-null  object\n",
      " 8   Cod_distrito         31927 non-null  object\n",
      " 9   Cod_meso             31927 non-null  object\n",
      " 10  Cod_micro            31927 non-null  object\n",
      " 11  Cod_municipio        31927 non-null  object\n",
      " 12  Cod_subdistrito      31927 non-null  object\n",
      "dtypes: object(13)\n",
      "memory usage: 3.4+ MB\n"
     ]
    }
   ],
   "source": [
    "options_vars = [col for col in data.dtypes.index if data.dtypes[col]=='object']\n",
    "data[options_vars].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# missing values\n",
    "order_index = data.isnull().sum(axis=1).sort_values(ascending=True).index\n",
    "order_col = data.isnull().sum(axis=0).sort_values(ascending=True).index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,9))\n",
    "sns.heatmap(data.loc[order_index, order_col].isnull(), cbar=False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No parece haber un problema de missing values en la base. Hay que revisar las variables que están a la derecha. las que muestran que si hay info para unas columnas y no para otras, pero no es una porción muy grande de la base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**eliminamos filas con NA's por tanto**\n",
    "\n",
    "\n",
    "**eliminamos rows con decision unefined**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "R    18628\n",
       "A    13097\n",
       "Name: final_decision, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fit = data.dropna()\n",
    "data_fit = data_fit[data_fit[\"final_decision\"]!= 'undefined']\n",
    "data_fit.final_decision.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#se realiza el fit solo sobre las variables de censo.. no se usan las otras \n",
    "# pues el modelo no debe discriminar por estado, distrito, etc\n",
    "####probar dropping lat y long\n",
    "\n",
    "\n",
    "col_names = [col for col in data.dtypes.index if data.dtypes[col]!='object' and col != \"final_decision\" and col not in ['lat','long']]\n",
    "features = data_fit[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>census_code</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>final_decision</th>\n",
       "      <th>Cod_setor</th>\n",
       "      <th>DOMICILIO_RENDA_V001</th>\n",
       "      <th>DOMICILIO_RENDA_V002</th>\n",
       "      <th>DOMICILIO_RENDA_V003</th>\n",
       "      <th>DOMICILIO_RENDA_V004</th>\n",
       "      <th>...</th>\n",
       "      <th>Tipo_setor_7</th>\n",
       "      <th>Tipo_setor_8</th>\n",
       "      <th>Situacao_setor_1</th>\n",
       "      <th>Situacao_setor_2</th>\n",
       "      <th>Situacao_setor_3</th>\n",
       "      <th>Situacao_setor_4</th>\n",
       "      <th>Situacao_setor_5</th>\n",
       "      <th>Situacao_setor_6</th>\n",
       "      <th>Situacao_setor_7</th>\n",
       "      <th>Situacao_setor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.263983</td>\n",
       "      <td>-50.247906</td>\n",
       "      <td>R</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.472855</td>\n",
       "      <td>-0.472405</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.265123</td>\n",
       "      <td>-50.255143</td>\n",
       "      <td>R</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.472855</td>\n",
       "      <td>-0.472405</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.266660</td>\n",
       "      <td>-50.254667</td>\n",
       "      <td>A</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.472855</td>\n",
       "      <td>-0.472405</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000058</td>\n",
       "      <td>-20.267959</td>\n",
       "      <td>-50.262205</td>\n",
       "      <td>R</td>\n",
       "      <td>351550905000058</td>\n",
       "      <td>0.370332</td>\n",
       "      <td>-0.350686</td>\n",
       "      <td>-0.351805</td>\n",
       "      <td>0.395586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000042</td>\n",
       "      <td>-20.268545</td>\n",
       "      <td>-50.241478</td>\n",
       "      <td>R</td>\n",
       "      <td>351550905000042</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.730477</td>\n",
       "      <td>-0.730038</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32127</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000062</td>\n",
       "      <td>-9.761259</td>\n",
       "      <td>-36.654615</td>\n",
       "      <td>R</td>\n",
       "      <td>270030005000062</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.423870</td>\n",
       "      <td>-0.423419</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32128</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-9.766242</td>\n",
       "      <td>-36.641586</td>\n",
       "      <td>R</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>1.455902</td>\n",
       "      <td>1.456432</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32129</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-9.766306</td>\n",
       "      <td>-36.643756</td>\n",
       "      <td>A</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>1.455902</td>\n",
       "      <td>1.456432</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32130</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-9.767589</td>\n",
       "      <td>-36.642200</td>\n",
       "      <td>R</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>1.455902</td>\n",
       "      <td>1.456432</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32131</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000054</td>\n",
       "      <td>-9.780055</td>\n",
       "      <td>-36.648540</td>\n",
       "      <td>R</td>\n",
       "      <td>270030005000054</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>0.379661</td>\n",
       "      <td>0.380146</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31725 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state      census_code        lat       long final_decision  \\\n",
       "0        sp  351550905000079 -20.263983 -50.247906              R   \n",
       "1        sp  351550905000079 -20.265123 -50.255143              R   \n",
       "2        sp  351550905000079 -20.266660 -50.254667              A   \n",
       "3        sp  351550905000058 -20.267959 -50.262205              R   \n",
       "4        sp  351550905000042 -20.268545 -50.241478              R   \n",
       "...     ...              ...        ...        ...            ...   \n",
       "32127    al  270030005000062  -9.761259 -36.654615              R   \n",
       "32128    al  270030005000058  -9.766242 -36.641586              R   \n",
       "32129    al  270030005000058  -9.766306 -36.643756              A   \n",
       "32130    al  270030005000058  -9.767589 -36.642200              R   \n",
       "32131    al  270030005000054  -9.780055 -36.648540              R   \n",
       "\n",
       "             Cod_setor  DOMICILIO_RENDA_V001  DOMICILIO_RENDA_V002  \\\n",
       "0      351550905000079             -0.104213             -0.472855   \n",
       "1      351550905000079             -0.104213             -0.472855   \n",
       "2      351550905000079             -0.104213             -0.472855   \n",
       "3      351550905000058              0.370332             -0.350686   \n",
       "4      351550905000042             -0.104213             -0.730477   \n",
       "...                ...                   ...                   ...   \n",
       "32127  270030005000062             -0.104213             -0.423870   \n",
       "32128  270030005000058             -0.104213              1.455902   \n",
       "32129  270030005000058             -0.104213              1.455902   \n",
       "32130  270030005000058             -0.104213              1.455902   \n",
       "32131  270030005000054             -0.104213              0.379661   \n",
       "\n",
       "       DOMICILIO_RENDA_V003  DOMICILIO_RENDA_V004  ...  Tipo_setor_7  \\\n",
       "0                 -0.472405             -0.168260  ...     -0.009725   \n",
       "1                 -0.472405             -0.168260  ...     -0.009725   \n",
       "2                 -0.472405             -0.168260  ...     -0.009725   \n",
       "3                 -0.351805              0.395586  ...     -0.009725   \n",
       "4                 -0.730038             -0.168260  ...     -0.009725   \n",
       "...                     ...                   ...  ...           ...   \n",
       "32127             -0.423419             -0.168260  ...     -0.009725   \n",
       "32128              1.456432             -0.168260  ...     -0.009725   \n",
       "32129              1.456432             -0.168260  ...     -0.009725   \n",
       "32130              1.456432             -0.168260  ...     -0.009725   \n",
       "32131              0.380146             -0.168260  ...     -0.009725   \n",
       "\n",
       "       Tipo_setor_8  Situacao_setor_1  Situacao_setor_2  Situacao_setor_3  \\\n",
       "0               0.0          0.188896         -0.144968         -0.056232   \n",
       "1               0.0          0.188896         -0.144968         -0.056232   \n",
       "2               0.0          0.188896         -0.144968         -0.056232   \n",
       "3               0.0          0.188896         -0.144968         -0.056232   \n",
       "4               0.0          0.188896         -0.144968         -0.056232   \n",
       "...             ...               ...               ...               ...   \n",
       "32127           0.0          0.188896         -0.144968         -0.056232   \n",
       "32128           0.0          0.188896         -0.144968         -0.056232   \n",
       "32129           0.0          0.188896         -0.144968         -0.056232   \n",
       "32130           0.0          0.188896         -0.144968         -0.056232   \n",
       "32131           0.0          0.188896         -0.144968         -0.056232   \n",
       "\n",
       "       Situacao_setor_4  Situacao_setor_5  Situacao_setor_6  Situacao_setor_7  \\\n",
       "0             -0.050594         -0.013754               0.0          -0.00794   \n",
       "1             -0.050594         -0.013754               0.0          -0.00794   \n",
       "2             -0.050594         -0.013754               0.0          -0.00794   \n",
       "3             -0.050594         -0.013754               0.0          -0.00794   \n",
       "4             -0.050594         -0.013754               0.0          -0.00794   \n",
       "...                 ...               ...               ...               ...   \n",
       "32127         -0.050594         -0.013754               0.0          -0.00794   \n",
       "32128         -0.050594         -0.013754               0.0          -0.00794   \n",
       "32129         -0.050594         -0.013754               0.0          -0.00794   \n",
       "32130         -0.050594         -0.013754               0.0          -0.00794   \n",
       "32131         -0.050594         -0.013754               0.0          -0.00794   \n",
       "\n",
       "       Situacao_setor_8  \n",
       "0             -0.089302  \n",
       "1             -0.089302  \n",
       "2             -0.089302  \n",
       "3             -0.089302  \n",
       "4             -0.089302  \n",
       "...                 ...  \n",
       "32127         -0.089302  \n",
       "32128         -0.089302  \n",
       "32129         -0.089302  \n",
       "32130         -0.089302  \n",
       "32131         -0.089302  \n",
       "\n",
       "[31725 rows x 190 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fit[col_names] = features\n",
    "data_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data_fit['final_decision'] = pd.to_numeric(data_fit.final_decision=='A').astype(np.int8)\n",
    "\n",
    "\n",
    "X = data_fit[col_names]\n",
    "y = data_fit['final_decision']\n",
    "\n",
    "\n",
    "\n",
    "#Create train and test sets\n",
    "#Create holdout/validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21)\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>census_code</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>final_decision</th>\n",
       "      <th>Cod_setor</th>\n",
       "      <th>DOMICILIO_RENDA_V001</th>\n",
       "      <th>DOMICILIO_RENDA_V002</th>\n",
       "      <th>DOMICILIO_RENDA_V003</th>\n",
       "      <th>DOMICILIO_RENDA_V004</th>\n",
       "      <th>...</th>\n",
       "      <th>Tipo_setor_7</th>\n",
       "      <th>Tipo_setor_8</th>\n",
       "      <th>Situacao_setor_1</th>\n",
       "      <th>Situacao_setor_2</th>\n",
       "      <th>Situacao_setor_3</th>\n",
       "      <th>Situacao_setor_4</th>\n",
       "      <th>Situacao_setor_5</th>\n",
       "      <th>Situacao_setor_6</th>\n",
       "      <th>Situacao_setor_7</th>\n",
       "      <th>Situacao_setor_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.263983</td>\n",
       "      <td>-50.247906</td>\n",
       "      <td>0</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.472855</td>\n",
       "      <td>-0.472405</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.265123</td>\n",
       "      <td>-50.255143</td>\n",
       "      <td>0</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.472855</td>\n",
       "      <td>-0.472405</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-20.266660</td>\n",
       "      <td>-50.254667</td>\n",
       "      <td>1</td>\n",
       "      <td>351550905000079</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.472855</td>\n",
       "      <td>-0.472405</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000058</td>\n",
       "      <td>-20.267959</td>\n",
       "      <td>-50.262205</td>\n",
       "      <td>0</td>\n",
       "      <td>351550905000058</td>\n",
       "      <td>0.370332</td>\n",
       "      <td>-0.350686</td>\n",
       "      <td>-0.351805</td>\n",
       "      <td>0.395586</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sp</td>\n",
       "      <td>351550905000042</td>\n",
       "      <td>-20.268545</td>\n",
       "      <td>-50.241478</td>\n",
       "      <td>0</td>\n",
       "      <td>351550905000042</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.730477</td>\n",
       "      <td>-0.730038</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32127</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000062</td>\n",
       "      <td>-9.761259</td>\n",
       "      <td>-36.654615</td>\n",
       "      <td>0</td>\n",
       "      <td>270030005000062</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>-0.423870</td>\n",
       "      <td>-0.423419</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32128</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-9.766242</td>\n",
       "      <td>-36.641586</td>\n",
       "      <td>0</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>1.455902</td>\n",
       "      <td>1.456432</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32129</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-9.766306</td>\n",
       "      <td>-36.643756</td>\n",
       "      <td>1</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>1.455902</td>\n",
       "      <td>1.456432</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32130</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-9.767589</td>\n",
       "      <td>-36.642200</td>\n",
       "      <td>0</td>\n",
       "      <td>270030005000058</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>1.455902</td>\n",
       "      <td>1.456432</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32131</th>\n",
       "      <td>al</td>\n",
       "      <td>270030005000054</td>\n",
       "      <td>-9.780055</td>\n",
       "      <td>-36.648540</td>\n",
       "      <td>0</td>\n",
       "      <td>270030005000054</td>\n",
       "      <td>-0.104213</td>\n",
       "      <td>0.379661</td>\n",
       "      <td>0.380146</td>\n",
       "      <td>-0.168260</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009725</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.188896</td>\n",
       "      <td>-0.144968</td>\n",
       "      <td>-0.056232</td>\n",
       "      <td>-0.050594</td>\n",
       "      <td>-0.013754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00794</td>\n",
       "      <td>-0.089302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31725 rows × 190 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state      census_code        lat       long  final_decision  \\\n",
       "0        sp  351550905000079 -20.263983 -50.247906               0   \n",
       "1        sp  351550905000079 -20.265123 -50.255143               0   \n",
       "2        sp  351550905000079 -20.266660 -50.254667               1   \n",
       "3        sp  351550905000058 -20.267959 -50.262205               0   \n",
       "4        sp  351550905000042 -20.268545 -50.241478               0   \n",
       "...     ...              ...        ...        ...             ...   \n",
       "32127    al  270030005000062  -9.761259 -36.654615               0   \n",
       "32128    al  270030005000058  -9.766242 -36.641586               0   \n",
       "32129    al  270030005000058  -9.766306 -36.643756               1   \n",
       "32130    al  270030005000058  -9.767589 -36.642200               0   \n",
       "32131    al  270030005000054  -9.780055 -36.648540               0   \n",
       "\n",
       "             Cod_setor  DOMICILIO_RENDA_V001  DOMICILIO_RENDA_V002  \\\n",
       "0      351550905000079             -0.104213             -0.472855   \n",
       "1      351550905000079             -0.104213             -0.472855   \n",
       "2      351550905000079             -0.104213             -0.472855   \n",
       "3      351550905000058              0.370332             -0.350686   \n",
       "4      351550905000042             -0.104213             -0.730477   \n",
       "...                ...                   ...                   ...   \n",
       "32127  270030005000062             -0.104213             -0.423870   \n",
       "32128  270030005000058             -0.104213              1.455902   \n",
       "32129  270030005000058             -0.104213              1.455902   \n",
       "32130  270030005000058             -0.104213              1.455902   \n",
       "32131  270030005000054             -0.104213              0.379661   \n",
       "\n",
       "       DOMICILIO_RENDA_V003  DOMICILIO_RENDA_V004  ...  Tipo_setor_7  \\\n",
       "0                 -0.472405             -0.168260  ...     -0.009725   \n",
       "1                 -0.472405             -0.168260  ...     -0.009725   \n",
       "2                 -0.472405             -0.168260  ...     -0.009725   \n",
       "3                 -0.351805              0.395586  ...     -0.009725   \n",
       "4                 -0.730038             -0.168260  ...     -0.009725   \n",
       "...                     ...                   ...  ...           ...   \n",
       "32127             -0.423419             -0.168260  ...     -0.009725   \n",
       "32128              1.456432             -0.168260  ...     -0.009725   \n",
       "32129              1.456432             -0.168260  ...     -0.009725   \n",
       "32130              1.456432             -0.168260  ...     -0.009725   \n",
       "32131              0.380146             -0.168260  ...     -0.009725   \n",
       "\n",
       "       Tipo_setor_8  Situacao_setor_1  Situacao_setor_2  Situacao_setor_3  \\\n",
       "0               0.0          0.188896         -0.144968         -0.056232   \n",
       "1               0.0          0.188896         -0.144968         -0.056232   \n",
       "2               0.0          0.188896         -0.144968         -0.056232   \n",
       "3               0.0          0.188896         -0.144968         -0.056232   \n",
       "4               0.0          0.188896         -0.144968         -0.056232   \n",
       "...             ...               ...               ...               ...   \n",
       "32127           0.0          0.188896         -0.144968         -0.056232   \n",
       "32128           0.0          0.188896         -0.144968         -0.056232   \n",
       "32129           0.0          0.188896         -0.144968         -0.056232   \n",
       "32130           0.0          0.188896         -0.144968         -0.056232   \n",
       "32131           0.0          0.188896         -0.144968         -0.056232   \n",
       "\n",
       "       Situacao_setor_4  Situacao_setor_5  Situacao_setor_6  Situacao_setor_7  \\\n",
       "0             -0.050594         -0.013754               0.0          -0.00794   \n",
       "1             -0.050594         -0.013754               0.0          -0.00794   \n",
       "2             -0.050594         -0.013754               0.0          -0.00794   \n",
       "3             -0.050594         -0.013754               0.0          -0.00794   \n",
       "4             -0.050594         -0.013754               0.0          -0.00794   \n",
       "...                 ...               ...               ...               ...   \n",
       "32127         -0.050594         -0.013754               0.0          -0.00794   \n",
       "32128         -0.050594         -0.013754               0.0          -0.00794   \n",
       "32129         -0.050594         -0.013754               0.0          -0.00794   \n",
       "32130         -0.050594         -0.013754               0.0          -0.00794   \n",
       "32131         -0.050594         -0.013754               0.0          -0.00794   \n",
       "\n",
       "       Situacao_setor_8  \n",
       "0             -0.089302  \n",
       "1             -0.089302  \n",
       "2             -0.089302  \n",
       "3             -0.089302  \n",
       "4             -0.089302  \n",
       "...                 ...  \n",
       "32127         -0.089302  \n",
       "32128         -0.089302  \n",
       "32129         -0.089302  \n",
       "32130         -0.089302  \n",
       "32131         -0.089302  \n",
       "\n",
       "[31725 rows x 190 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel no lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned Logistic Regression Parameters: {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "Best score is 0.6962959903705856\n"
     ]
    }
   ],
   "source": [
    "# Setup the hyperparameter grid\n",
    "param_grid = [{'kernel': ['rbf'], 'gamma': [0.1, 1, 10, 100],\n",
    "                     'C': [0.1, 1, 10, 100, 1000] }]\n",
    "\n",
    "# Instantiate a SVC classifier: \n",
    "svc = SVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "svm_cv = GridSearchCV(svc, param_grid, cv=7)\n",
    "\n",
    "# Fit it to the data\n",
    "svm_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned svm Parameters: {}\".format(svm_cv.best_params_))\n",
    "print(\"Best score is {}\".format(svm_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3035  723]\n",
      " [1160 1427]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.81      0.76      3758\n",
      "           1       0.66      0.55      0.60      2587\n",
      "\n",
      "    accuracy                           0.70      6345\n",
      "   macro avg       0.69      0.68      0.68      6345\n",
      "weighted avg       0.70      0.70      0.70      6345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = svm_cv.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kernel lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:532: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n",
      "/Users/felipetellez/opt/anaconda3/envs/team_5_ds4a/lib/python3.8/site-packages/sklearn/svm/_base.py:946: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuned svm Parameters: {'C': 0.001, 'loss': 'squared_hinge', 'penalty': 'l2'}\n",
      "Best score is 0.7170212765957448\n"
     ]
    }
   ],
   "source": [
    "# Setup the hyperparameter grid\n",
    "param_grid = [{'C': [0.001,0.01,1,10,100],\n",
    "               'penalty': ['l1', 'l2'],\n",
    "              'loss': ['hinge', 'squared_hinge']}]\n",
    "                \n",
    "# Instantiate a SVC classifier: \n",
    "svc = LinearSVC()\n",
    "\n",
    "# Instantiate the GridSearchCV object: logreg_cv\n",
    "svm_cv = GridSearchCV(svc, param_grid, cv=5)\n",
    "\n",
    "# Fit it to the data\n",
    "svm_cv.fit(X_train, y_train)\n",
    "\n",
    "# Print the tuned parameter and score\n",
    "print(\"Tuned svm Parameters: {}\".format(svm_cv.best_params_))\n",
    "print(\"Best score is {}\".format(svm_cv.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3188  570]\n",
      " [1203 1384]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.85      0.78      3758\n",
      "           1       0.71      0.53      0.61      2587\n",
      "\n",
      "    accuracy                           0.72      6345\n",
      "   macro avg       0.72      0.69      0.70      6345\n",
      "weighted avg       0.72      0.72      0.71      6345\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Predict the labels of the test set: y_pred\n",
    "y_pred = svm_cv.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
